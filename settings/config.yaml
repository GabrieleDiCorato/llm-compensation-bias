# HTTP Settings
timeout_seconds: 90

# LLM Providers Configuration
providers:
  - provider: "github"
    api_key_name: "GITHUB_TOKEN"
    url: "https://models.github.ai/inference/chat/completions"

# Available Models Configuration
models_settings:
  - model_id: "openai/gpt-4.1"
    provider: "github"
    additional_settings:
      # temperature: 0.7
      # max_tokens: 4096
      # top_p: 1.0
  - model_id: "openai/gpt-5-nano"
    provider: "github"
    additional_settings:
  - model_id: "DeepSeek-R1-0528"
    provider: "github"
    additional_settings:
  - model_id: "xai/grok-3"
    provider: "github"
    additional_settings:

# Enabled Models (subset of models_settings)
enabled_models:
  - "openai/gpt-4.1"
  - "openai/gpt-5-nano"
  - "DeepSeek-R1-0528"
  - "xai/grok-3"

# Prompt Configuration
prompt_directory: "settings/prompts"
prompt_strategies:
  - "neutral"
  - "fair"
  - "realistic"

# Output Settings
output_dir: "src/auto_generated"